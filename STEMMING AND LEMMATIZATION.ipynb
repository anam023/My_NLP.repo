{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T08:17:45.369811Z",
     "start_time": "2020-12-29T08:17:41.903340Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T09:27:07.867157Z",
     "start_time": "2020-12-29T09:27:06.383889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Anam\n",
      "[nltk_data]     Fatima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the technique used to extract the base form of the words by removing affixes from them.\n",
    "Stemming is not very useful beacause sometimes it resolve different words to a same stem or same form of words to different stems.\n",
    "\n",
    "There are 4 different types of stemming.\n",
    "1. Potter stemming\n",
    "2. Snowball stemming\n",
    "3. Lancaster stemming\n",
    "4. Regular Expression stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T08:47:47.943142Z",
     "start_time": "2020-12-29T08:47:47.936126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['write', 'hike', 'mixer', 'eat', 'baker', 'creat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PORTER STEMMER\n",
    "#it is very gentle and oldest stemming algorithm. \n",
    "#It's main concern is removing common ending of words so they can be resolved to a common form.\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps= PorterStemmer()\n",
    "li=['writing','hiking','mixer','eats','baker','creates']\n",
    "[ps.stem(word) for word in li]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T08:53:37.309700Z",
     "start_time": "2020-12-29T08:53:37.298729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n",
      "bonjour\n"
     ]
    }
   ],
   "source": [
    "#SNOWBAL STEMMER\n",
    "# also known as the Porter Stemmer2, it is more aggressive than Porter Stemmer.\n",
    "#it supports 15 non english languages\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "print(SnowballStemmer.languages)\n",
    "french_stemmer= SnowballStemmer('french')\n",
    "print(french_stemmer.stem('bonjoura'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T09:05:45.213519Z",
     "start_time": "2020-12-29T09:05:45.194953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lancaster Stemmer\n",
    "# it is the most aggressive stemming algorithm\n",
    "# we can add our own custom rules to this algorithm\n",
    "# one drwback of this algo is that sometimes it becomes overly aggressive and really can transform words into strange stems\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls= LancasterStemmer()\n",
    "ls.stem('eats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T09:11:25.252443Z",
     "start_time": "2020-12-29T09:11:25.240475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat', 'eat', 'eats']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regular Expression Stemming Algorithm\n",
    "# it basically takes a single regular expression and removes any suffix or prefix that matches the expression\n",
    "\n",
    "from nltk.stem import RegexpStemmer\n",
    "rs= RegexpStemmer('ing')\n",
    "li= ['eating','ingeat','eats']  #it will stem only those words which have ing as suffix or prefix\n",
    "[rs.stem(words) for words in li]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is a calculated process, it involves resolving words to their dictionary form(lemma).\n",
    "for lemmatization to resolve a word to its lemma, it needs to know the part of speech, \n",
    "whcich require extra linguistic computational power. Lemmatizers require a lot more knowledge about the structure of a language\n",
    "therefore it is harder to create a lemmatizer in a new language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T09:27:17.840222Z",
     "start_time": "2020-12-29T09:27:16.513790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lm=WordNetLemmatizer()\n",
    "lm.lemmatize('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
